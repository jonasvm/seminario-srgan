{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# @title SRGAN (x4, Y-channel, VGG19 φ5,4, 16 blocos)\n",
        "# @markdown Este notebook:\n",
        "# @markdown 1) Baixa um mini-conjunto de imagens (5 imagens \"HR\")\n",
        "# @markdown 2) Gera \"LR\" com bicúbica ×4 (fiel ao procedimento do paper)\n",
        "# @markdown 3) Define Gerador (SRResNet-16) e Discriminador\n",
        "# @markdown 4) Pré-treina o Gerador com MSE (poucos passos) e treina SRGAN (poucos passos)\n",
        "# @markdown 5) Avalia PSNR/SSIM no canal Y com recorte de borda de 4 px (como no paper)\n",
        "\n",
        "import os, math, random, urllib.request, zipfile, io\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import vgg19, VGG19_Weights\n",
        "from torchvision import transforms\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr_metric\n",
        "from skimage.metrics import structural_similarity as ssim_metric"
      ],
      "metadata": {
        "id": "_6I1nE-v56yT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 0) Configurações\n",
        "# =========================\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "UPSCALE = 4                 # fator x4\n",
        "PATCH_HR = 96               # como no paper (patches 96x96 HR na etapa de treino)\n",
        "BATCH_SIZE = 4              # pequeno para rodar em CPU também\n",
        "WORKERS = 2\n",
        "\n",
        "G_PRETRAIN_STEPS = 200      # PARA DEMO: passos reduzidos (paper usou 1e6)\n",
        "GAN_TRAIN_STEPS = 200       # PARA DEMO: passos reduzidos (paper usou 2e5 total)\n",
        "G_LR_1 = 1e-4               # lr inicial\n",
        "G_LR_2 = 1e-5               # (para treino longo; não usamos aqui)\n",
        "D_LR = 1e-4\n",
        "\n",
        "# Reprodutibilidade básica\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "root = Path(\"./srgan_demo\")\n",
        "(root / \"data/hr\").mkdir(parents=True, exist_ok=True)\n",
        "(root / \"out\").mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "Z4_2vLCo6XyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# 1) Mini dataset (5 imagens HR)\n",
        "# ==============================\n",
        "!pip -q install scikit-image\n",
        "\n",
        "from skimage import data\n",
        "import numpy as np\n",
        "\n",
        "hr_dir = root / \"data/hr\"\n",
        "(hr_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def to_rgb(img):\n",
        "    # garante RGB mesmo se vier em grayscale\n",
        "    if img.ndim == 2:\n",
        "        img = np.stack([img, img, img], axis=-1)\n",
        "    if img.shape[2] == 4:\n",
        "        img = img[:, :, :3]\n",
        "    return img\n",
        "\n",
        "def save_img(arr, path):\n",
        "    arr = np.clip(arr, 0, 255).astype(np.uint8)\n",
        "    Image.fromarray(arr).save(path)\n",
        "\n",
        "# pega 5 imagens estáveis do scikit-image\n",
        "imgs = [\n",
        "    data.astronaut(),  # 512x512\n",
        "    data.coffee(),     # 400x600\n",
        "    data.chelsea(),    # 300x451\n",
        "    data.rocket(),     # 427x640\n",
        "    data.camera(),     # 512x512 (grayscale)\n",
        "]\n",
        "# converte e ajusta para múltiplo de 4 (requisito do upscale x4)\n",
        "for i, im in enumerate(imgs, 1):\n",
        "    im = to_rgb(im)\n",
        "    H, W = im.shape[:2]\n",
        "    H = (H // UPSCALE) * UPSCALE\n",
        "    W = (W // UPSCALE) * UPSCALE\n",
        "    if (H, W) != im.shape[:2]:\n",
        "        im = np.array(Image.fromarray(im).resize((W, H), Image.BICUBIC))\n",
        "    save_img(im, hr_dir / f\"img_{i:02d}.png\")\n",
        "\n",
        "print(\"✅ Dataset HR pronto em\", hr_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAW7V34h6bk1",
        "outputId": "f56c6e75-f7b4-4e92-f9da-621b8031ea03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset HR pronto em srgan_demo/data/hr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# 2) Utilitários de imagem (YCbCr, canal Y, bicúbica ×4)\n",
        "# ======================================================\n",
        "def rgb_to_ycbcr(img: np.ndarray):\n",
        "    # img float32 [0,1]\n",
        "    # fórmula ITU-R BT.601 (aprox), retorna em [0,1]\n",
        "    r, g, b = img[...,0], img[...,1], img[...,2]\n",
        "    y  = 0.299*r + 0.587*g + 0.114*b\n",
        "    cb = -0.168736*r - 0.331264*g + 0.5*b + 0.5\n",
        "    cr = 0.5*r - 0.418688*g - 0.081312*b + 0.5\n",
        "    return np.stack([y, cb, cr], axis=-1)\n",
        "\n",
        "def ycbcr_to_rgb(img: np.ndarray):\n",
        "    # img float32 [0,1]\n",
        "    y, cb, cr = img[...,0], img[...,1]-0.5, img[...,2]-0.5\n",
        "    r = y + 1.402*cr\n",
        "    g = y - 0.344136*cb - 0.714136*cr\n",
        "    b = y + 1.772*cb\n",
        "    out = np.stack([r, g, b], axis=-1)\n",
        "    return np.clip(out, 0.0, 1.0)\n",
        "\n",
        "def pil_to_np(img_pil):\n",
        "    return np.array(img_pil).astype(np.float32) / 255.0\n",
        "\n",
        "def np_to_pil(img_np):\n",
        "    img = np.clip(img_np*255.0, 0, 255).astype(np.uint8)\n",
        "    return Image.fromarray(img)\n",
        "\n",
        "def make_lr_bicubic(hr_img_pil, scale=4):\n",
        "    w, h = hr_img_pil.size\n",
        "    lr = hr_img_pil.resize((w//scale, h//scale), Image.BICUBIC)\n",
        "    return lr\n",
        "\n",
        "# crop de avaliação: remove 4px de borda no HR (paper)\n",
        "def shave(img: np.ndarray, border=4):\n",
        "    return img[border:-border, border:-border, :]"
      ],
      "metadata": {
        "id": "44XbWjpV7oI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================================================\n",
        "# 3) Dataset (gera patches 96x96 HR e LR bicúbica x4)\n",
        "#    Notas do paper: patches HR 96x96, LR via bicúbica r=4,\n",
        "#    normalização LR [0,1], HR [-1,1] (para MSE):contentReference[oaicite:1]{index=1}.\n",
        "# ====================================================================================================\n",
        "class SRPatches(Dataset):\n",
        "    def __init__(self, hr_dir, patch=96, scale=4, n_patches_per_img=20, split=\"train\"):\n",
        "        self.hr_paths = sorted([str((Path(hr_dir)/p)) for p in os.listdir(hr_dir) if p.lower().endswith(\".png\")])\n",
        "        self.patch = patch\n",
        "        self.scale = scale\n",
        "        self.n = n_patches_per_img\n",
        "        self.split = split\n",
        "        # carregamos em memória para facilitar\n",
        "        self.hr_imgs = [Image.open(p).convert(\"RGB\") for p in self.hr_paths]\n",
        "        # para \"val\", não queremos patching aleatório — usaremos full frame\n",
        "    def __len__(self):\n",
        "        if self.split == \"train\":\n",
        "            return len(self.hr_imgs) * self.n\n",
        "        return len(self.hr_imgs)\n",
        "    def __getitem__(self, idx):\n",
        "        if self.split == \"train\":\n",
        "            img = random.choice(self.hr_imgs)\n",
        "            W, H = img.size\n",
        "            # escolhe um patch HR de tamanho patch, múltiplo de scale\n",
        "            x = random.randint(0, W - self.patch)\n",
        "            y = random.randint(0, H - self.patch)\n",
        "            hr = img.crop((x, y, x+self.patch, y+self.patch))\n",
        "        else:\n",
        "            # validação: usa a imagem inteira (ajusta para múltiplo de scale)\n",
        "            img = self.hr_imgs[idx]\n",
        "            W, H = img.size\n",
        "            W = (W // self.scale) * self.scale\n",
        "            H = (H // self.scale) * self.scale\n",
        "            hr = img.resize((W, H), Image.BICUBIC)\n",
        "\n",
        "        # gera LR bicúbica\n",
        "        lr = make_lr_bicubic(hr, scale=self.scale)\n",
        "\n",
        "        # tensores: a rede trabalha em RGB; avaliação será em Y\n",
        "        to_t = transforms.ToTensor()  # [0,1]\n",
        "        lr_t = to_t(lr)                          # [0,1]\n",
        "        hr_t = to_t(hr)*2.0 - 1.0                # [-1,1] (paper para MSE):contentReference[oaicite:2]{index=2}\n",
        "\n",
        "        return lr_t, hr_t\n",
        "\n",
        "train_ds = SRPatches(hr_dir, PATCH_HR, UPSCALE, n_patches_per_img=20, split=\"train\")\n",
        "val_ds   = SRPatches(hr_dir, PATCH_HR, UPSCALE, split=\"val\")\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=WORKERS, drop_last=True)\n",
        "val_dl   = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=0)"
      ],
      "metadata": {
        "id": "8DwIl8aX7rOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================================================\n",
        "# 4) Modelos (Gerador SRResNet-16 + Discriminador)\n",
        "#    Fiel ao paper: blocos residuais 3x3/64 + BN + PReLU; PixelShuffle para upsample ×4;\n",
        "#    Discriminador com convs 3x3, canais 64→512, strides, LeakyReLU(0.2), FC + sigmoid:contentReference[oaicite:3]{index=3}.\n",
        "# ====================================================================================================\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels=64):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(channels, channels, 3, 1, 1)\n",
        "        self.bn1   = nn.BatchNorm2d(channels)\n",
        "        self.prelu = nn.PReLU()\n",
        "        self.conv2 = nn.Conv2d(channels, channels, 3, 1, 1)\n",
        "        self.bn2   = nn.BatchNorm2d(channels)\n",
        "    def forward(self, x):\n",
        "        out = self.prelu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        return x + out\n",
        "\n",
        "class UpsampleBlock(nn.Module):\n",
        "    def __init__(self, in_ch=64, scale=2):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_ch, in_ch * (scale ** 2), 3, 1, 1)\n",
        "        self.ps   = nn.PixelShuffle(scale)\n",
        "        self.prelu= nn.PReLU()\n",
        "    def forward(self, x):\n",
        "        return self.prelu(self.ps(self.conv(x)))\n",
        "\n",
        "class GeneratorSRResNet16(nn.Module):\n",
        "    def __init__(self, n_blocks=16, in_ch=3, out_ch=3):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_ch, 64, 9, 1, 4)  # kernel 9x9 comum em SRResNet inicial\n",
        "        self.prelu = nn.PReLU()\n",
        "        self.resblocks = nn.Sequential(*[ResidualBlock(64) for _ in range(n_blocks)])\n",
        "        self.conv2 = nn.Conv2d(64, 64, 3, 1, 1)\n",
        "        self.bn2   = nn.BatchNorm2d(64)\n",
        "        # dois upsample ×2 → ×4 total\n",
        "        self.up1 = UpsampleBlock(64, 2)\n",
        "        self.up2 = UpsampleBlock(64, 2)\n",
        "        self.conv3 = nn.Conv2d(64, out_ch, 9, 1, 4)\n",
        "    def forward(self, x):\n",
        "        x1 = self.prelu(self.conv1(x))\n",
        "        xr = self.resblocks(x1)\n",
        "        x2 = self.bn2(self.conv2(xr))\n",
        "        x = x1 + x2\n",
        "        x = self.up1(x)\n",
        "        x = self.up2(x)\n",
        "        x = torch.tanh(self.conv3(x))  # [-1,1]\n",
        "        return x\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_ch=3):\n",
        "        super().__init__()\n",
        "        def block(i, o, k=3, s=1, p=1, bn=True):\n",
        "            layers = [nn.Conv2d(i,o,k,s,p)]\n",
        "            if bn: layers += [nn.BatchNorm2d(o)]\n",
        "            layers += [nn.LeakyReLU(0.2, inplace=True)]\n",
        "            return nn.Sequential(*layers)\n",
        "        self.features = nn.Sequential(\n",
        "            block(in_ch, 64, 3, 1, 1, bn=False),\n",
        "            block(64, 64, 3, 2, 1, bn=True),\n",
        "            block(64, 128, 3, 1, 1, bn=True),\n",
        "            block(128,128,3, 2, 1, bn=True),\n",
        "            block(128,256,3, 1, 1, bn=True),\n",
        "            block(256,256,3, 2, 1, bn=True),\n",
        "            block(256,512,3, 1, 1, bn=True),\n",
        "            block(512,512,3, 2, 1, bn=True),\n",
        "        )\n",
        "        # descobre automaticamente o flatten_dim com um forward “seco”\n",
        "        with torch.no_grad():\n",
        "            dummy = torch.zeros(1, 3, PATCH_HR, PATCH_HR)\n",
        "            f = self.features(dummy)\n",
        "            flatten_dim = f.numel()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(flatten_dim, 1024),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(1024, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        f = self.features(x)\n",
        "        return self.classifier(f)\n",
        "G = GeneratorSRResNet16().to(DEVICE)\n",
        "D = Discriminator().to(DEVICE)"
      ],
      "metadata": {
        "id": "r_KY2ehe7u2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 5) Perdas\n",
        "#    - Content loss VGG19 φ5,4 (relu5_4)\n",
        "#    - Adversarial loss: -log D(G(x))  (usamos BCE)\n",
        "#    - Pré-treino G com MSE em RGB (paper pré-treinou com MSE):contentReference[oaicite:4]{index=4}\n",
        "# =========================\n",
        "# VGG19 para feature extraction\n",
        "vgg = vgg19(weights=VGG19_Weights.IMAGENET1K_V1).features.to(DEVICE).eval()\n",
        "for p in vgg.parameters(): p.requires_grad = False\n",
        "\n",
        "# índice da relu5_4 em torchvision (features)\n",
        "# VGG19 layers: conv1_1=0, relu1_1=1, ..., relu5_4=34 (conv5_4=34? relu5_4 ~ 35-36 dependendo da versão)\n",
        "# No torchvision, o bloco final tem indices até 36; pegaremos features até relu5_4 inclusive.\n",
        "VGG_FEATURE_LAYER = 35  # ajusta para capturar relu5_4 (pode variar por versão)\n",
        "def vgg54_feats(x):\n",
        "    # espera x em [0,1], normalizado como ImageNet\n",
        "    # converter de [-1,1] p/ [0,1]\n",
        "    x = (x + 1.0)/2.0\n",
        "    norm = transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std =[0.229, 0.224, 0.225]\n",
        "    )\n",
        "    x = torch.stack([norm(xi) for xi in x], dim=0)\n",
        "    return vgg[:VGG_FEATURE_LAYER](x)\n",
        "\n",
        "bce = nn.BCELoss()\n",
        "mse = nn.MSELoss()\n",
        "\n",
        "opt_G_pre = torch.optim.Adam(G.parameters(), lr=G_LR_1, betas=(0.9, 0.999))\n",
        "opt_G     = torch.optim.Adam(G.parameters(), lr=G_LR_1, betas=(0.9, 0.999))\n",
        "opt_D     = torch.optim.Adam(D.parameters(), lr=D_LR,   betas=(0.9, 0.999))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cl-9tM2-8CWb",
        "outputId": "e3822dc3-41ec-4b90-fd43-f93ab8911c10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 548M/548M [00:07<00:00, 73.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 6) Pré-treino do Gerador (MSE)\n",
        "# =========================\n",
        "G.train()\n",
        "for step, (lr_t, hr_t) in enumerate(train_dl, 1):\n",
        "    lr_t, hr_t = lr_t.to(DEVICE), hr_t.to(DEVICE)\n",
        "    sr_t = G(lr_t)\n",
        "    loss = mse(sr_t, hr_t)  # MSE no espaço RGB (com HR em [-1,1])\n",
        "    opt_G_pre.zero_grad()\n",
        "    loss.backward()\n",
        "    opt_G_pre.step()\n",
        "    if step % 50 == 0:\n",
        "        print(f\"[G-pre] step {step}/{G_PRETRAIN_STEPS}  MSE: {loss.item():.4f}\")\n",
        "    if step >= G_PRETRAIN_STEPS:\n",
        "        break"
      ],
      "metadata": {
        "id": "QIXHtN8Z8HCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 7) Treino adversarial (SRGAN) — (content VGG54 + 1e-3 * adversarial)\n",
        "# =========================\n",
        "G.train(); D.train()\n",
        "\n",
        "def real_fake_labels(bs):\n",
        "    return torch.ones(bs,1,device=DEVICE), torch.zeros(bs,1,device=DEVICE)\n",
        "\n",
        "ADV_WEIGHT = 1e-3  # como no paper para escalar o termo adversarial:contentReference[oaicite:5]{index=5}\n",
        "\n",
        "step = 0\n",
        "while step < GAN_TRAIN_STEPS:\n",
        "    for lr_t, hr_t in train_dl:\n",
        "        step += 1\n",
        "        lr_t, hr_t = lr_t.to(DEVICE), hr_t.to(DEVICE)\n",
        "        bs = lr_t.size(0)\n",
        "\n",
        "        # === Atualiza D ===\n",
        "        with torch.no_grad():\n",
        "            sr_t = G(lr_t)\n",
        "        D_real = D((hr_t + 1)/2)   # D espera [0,1]; convertendo HR [-1,1] → [0,1]\n",
        "        D_fake = D((sr_t + 1)/2)   # idem para SR\n",
        "        y_real, y_fake = real_fake_labels(bs)\n",
        "        loss_D = bce(D_real, y_real) + bce(D_fake, y_fake)\n",
        "        opt_D.zero_grad()\n",
        "        loss_D.backward()\n",
        "        opt_D.step()\n",
        "\n",
        "        # === Atualiza G ===\n",
        "        sr_t = G(lr_t)\n",
        "        D_fake = D((sr_t + 1)/2)\n",
        "        # content loss: VGG19 φ5,4 (euclidiana)\n",
        "        f_sr = vgg54_feats(sr_t)\n",
        "        f_hr = vgg54_feats(hr_t)\n",
        "        content_loss = mse(f_sr, f_hr)\n",
        "        adv_loss = bce(D_fake, y_real)  # -log(D(G)) ~ BCE com target=1\n",
        "        loss_G = content_loss + ADV_WEIGHT * adv_loss\n",
        "\n",
        "        opt_G.zero_grad()\n",
        "        loss_G.backward()\n",
        "        opt_G.step()\n",
        "\n",
        "        if step % 50 == 0:\n",
        "            print(f\"[GAN] step {step}/{GAN_TRAIN_STEPS}  \"\n",
        "                  f\"content(VGG54): {content_loss.item():.4f}  \"\n",
        "                  f\"adv: {adv_loss.item():.4f}  D: {loss_D.item():.4f}\")\n",
        "        if step >= GAN_TRAIN_STEPS:\n",
        "            break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEQBNWRI8l0L",
        "outputId": "aad0929a-205e-4753-c91c-03e192f1b108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAN] step 50/200  content(VGG54): 12.5854  adv: 24.7100  D: 0.0000\n",
            "[GAN] step 100/200  content(VGG54): 36.0304  adv: 21.7004  D: 0.0003\n",
            "[GAN] step 150/200  content(VGG54): 15.1095  adv: 18.2490  D: 0.0001\n",
            "[GAN] step 200/200  content(VGG54): 13.1520  adv: 30.5570  D: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUp67UwozGnr",
        "outputId": "747cacb8-3b5d-446d-d123-3c9426fe7e75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESULTADOS (demo) — Y-channel, crop 4 px, x4:  PSNR=8.54 dB  SSIM=0.0635\n",
            "\n",
            "Saídas de exemplo salvas em: srgan_demo/out\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# 8) Avaliação: PSNR/SSIM no canal Y com recorte de 4 px (fiel ao paper)\n",
        "# =========================\n",
        "G.eval()\n",
        "def evaluate_model(G, loader, save_examples=3):\n",
        "    G.eval()\n",
        "    all_psnr, all_ssim = [], []\n",
        "    saved = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (lr_t, hr_t) in enumerate(loader):\n",
        "            lr_t = lr_t.to(DEVICE)\n",
        "            sr_t = G(lr_t).clamp(-1,1)\n",
        "            # converte tensores para imagens numpy [0,1] RGB\n",
        "            sr = (sr_t[0].permute(1,2,0).cpu().numpy() + 1)/2\n",
        "            hr = (hr_t[0].permute(1,2,0).cpu().numpy() + 1)/2\n",
        "\n",
        "            # converte para YCbCr, pega Y\n",
        "            sr_y = rgb_to_ycbcr(sr)[...,0:1]\n",
        "            hr_y = rgb_to_ycbcr(hr)[...,0:1]\n",
        "\n",
        "            # crop borda de 4 px (avaliar região válida)\n",
        "            sr_y_c = shave(sr_y, 4)\n",
        "            hr_y_c = shave(hr_y, 4)\n",
        "\n",
        "            psnr_val = psnr_metric(hr_y_c, sr_y_c, data_range=1.0)\n",
        "            ssim_val = ssim_metric(hr_y_c.squeeze(), sr_y_c.squeeze(), data_range=1.0)\n",
        "            all_psnr.append(psnr_val)\n",
        "            all_ssim.append(ssim_val)\n",
        "\n",
        "            # salva alguns exemplos\n",
        "            if saved < save_examples:\n",
        "                out_p = root / \"out\" / f\"sr_{i:02d}.png\"\n",
        "                np_to_pil(sr).save(out_p)\n",
        "                saved += 1\n",
        "    return float(np.mean(all_psnr)), float(np.mean(all_ssim))\n",
        "\n",
        "mean_psnr, mean_ssim = evaluate_model(G, val_dl, save_examples=3)\n",
        "print(f\"RESULTADOS (demo) — Y-channel, crop 4 px, x{UPSCALE}:  PSNR={mean_psnr:.2f} dB  SSIM={mean_ssim:.4f}\")\n",
        "\n",
        "print(f\"\\nSaídas de exemplo salvas em: {root/'out'}\")\n",
        "\n",
        "# =========================\n",
        "# 9) Observações de fidelidade:\n",
        "# - Arquitetura do Gerador: 16 blocos residuais, BN, PReLU, PixelShuffle ×4 (SRResNet) ✓\n",
        "# - Discriminador: convs 3x3, canais 64→512, strides, LeakyReLU(0.2), MLP final + sigmoid ✓\n",
        "# - Perdas: Content (VGG19 φ5,4) + 1e-3 * adversarial (BCE com target=1) ✓\n",
        "# - Pré-treino do G com MSE; depois adversarial alternando G/D (k=1) ✓\n",
        "# - Dados: LR gerado por bicúbica ×4; avaliação no canal Y com crop 4 px ✓\n",
        "# - Escala reduzida para ser rápido; para resultados fortes, aumente passos/épocas e use banco grande (p.ex. DIV2K/ImageNet).\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Caminho da pasta\n",
        "folder_path = \"/content/srgan_demo/out\"\n",
        "zip_path = \"/content/srgan_out.zip\"\n",
        "\n",
        "# Compacta toda a pasta em um arquivo .zip\n",
        "shutil.make_archive(\"/content/srgan_out\", 'zip', folder_path)\n",
        "\n",
        "# Faz o download do .zip\n",
        "files.download(zip_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "h7hDr8HwDWBm",
        "outputId": "455232c7-26eb-4994-8b12-18bbcf34343e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fe9c5a8d-2f33-45f6-bf41-75662cfee4c5\", \"srgan_out.zip\", 1451102)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 8) Avaliação (fiel ao paper)\n",
        "# =========================\n",
        "import csv\n",
        "from PIL import ImageDraw, ImageFont\n",
        "\n",
        "G.eval()\n",
        "\n",
        "def make_bicubic_from_lr(lr_rgb, scale=4):\n",
        "    \"\"\"Upscale LR (RGB [0,1]) para o tamanho HR com bicúbica, para baseline de comparação.\"\"\"\n",
        "    h, w = lr_rgb.shape[:2]\n",
        "    up = np.array(Image.fromarray((lr_rgb*255).astype(np.uint8)).resize((w*scale, h*scale), Image.BICUBIC)).astype(np.float32)/255.0\n",
        "    return up\n",
        "\n",
        "def concat_horiz(imgs, labels=(\"Bicubic\", \"SRGAN\", \"HR\")):\n",
        "    \"\"\"Concatena imagens horizontalmente e adiciona legendas sobre fundo preto.\"\"\"\n",
        "    pil_imgs = [np_to_pil(im) for im in imgs]\n",
        "    widths, heights = zip(*(im.size for im in pil_imgs))\n",
        "    H = max(heights)\n",
        "    W = sum(widths)\n",
        "    out = Image.new('RGB', (W, H + 30), color=(0, 0, 0))  # faixa preta para legenda\n",
        "    x = 0\n",
        "    draw = ImageDraw.Draw(out)\n",
        "\n",
        "    try:\n",
        "        font = ImageFont.truetype(\"DejaVuSans-Bold.ttf\", 16)\n",
        "    except:\n",
        "        font = ImageFont.load_default()\n",
        "\n",
        "    for idx, im in enumerate(pil_imgs):\n",
        "        out.paste(im, (x, 30))\n",
        "        w, h = im.size\n",
        "        label = labels[idx] if idx < len(labels) else f\"img{idx}\"\n",
        "\n",
        "        # Usa textbbox se disponível, senão textsize (compatibilidade Pillow)\n",
        "        if hasattr(draw, \"textbbox\"):\n",
        "            bbox = draw.textbbox((0, 0), label, font=font)\n",
        "            text_w = bbox[2] - bbox[0]\n",
        "            text_h = bbox[3] - bbox[1]\n",
        "        else:\n",
        "            text_w, text_h = draw.textsize(label, font=font)\n",
        "\n",
        "        draw.text(\n",
        "            (x + (w - text_w) // 2, (30 - text_h) // 2),\n",
        "            label,\n",
        "            font=font,\n",
        "            fill=(255, 255, 255)\n",
        "        )\n",
        "        x += w\n",
        "    return out\n",
        "\n",
        "def central_crop_box(H, W, min_size=128):\n",
        "    \"\"\"Define uma caixa central (x0,y0,larg,alt) para a 'mesma fatia' em HR.\n",
        "       Se a imagem for pequena, usa min(H,W)//3.\"\"\"\n",
        "    size = max(min_size, min(H, W)//3)\n",
        "    size = min(size, H, W)  # garante que cabe\n",
        "    x0 = (W - size) // 2\n",
        "    y0 = (H - size) // 2\n",
        "    return (x0, y0, size, size)\n",
        "\n",
        "def crop_by_box(img, box):\n",
        "    \"\"\"Recorta img (RGB [0,1]) pela caixa (x0,y0,w,h).\"\"\"\n",
        "    x0, y0, w, h = box\n",
        "    return img[y0:y0+h, x0:x0+w, :]\n",
        "\n",
        "def evaluate_model(G, loader, dataset_for_names, save_examples=3):\n",
        "    G.eval()\n",
        "    all_psnr, all_ssim = [], []\n",
        "    saved = 0\n",
        "\n",
        "    info_rows = []\n",
        "    out_dir = root / \"out\"\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    csv_path = out_dir / \"examples_info.csv\"\n",
        "\n",
        "    with torch.no_grad(), open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as fcsv:\n",
        "        writer = csv.writer(fcsv)\n",
        "        writer.writerow([\n",
        "            \"idx\",\"original_hr_path\",\"sr_path\",\"hr_path\",\"bicubic_path\",\n",
        "            \"compare_full_path\",\"compare_patch_path\",\"psnr_y\",\"ssim_y\",\"crop_box_(x0,y0,w,h)\"\n",
        "        ])\n",
        "\n",
        "        for i, (lr_t, hr_t) in enumerate(loader):\n",
        "            lr_t = lr_t.to(DEVICE)\n",
        "            sr_t = G(lr_t).clamp(-1,1)\n",
        "\n",
        "            # Tensores → numpy RGB [0,1]\n",
        "            sr = (sr_t[0].permute(1,2,0).cpu().numpy() + 1)/2\n",
        "            hr = (hr_t[0].permute(1,2,0).cpu().numpy() + 1)/2\n",
        "            # LR chega menor; upsample bicúbico para baseline (mesmo tamanho do HR/SR)\n",
        "            lr_rgb = lr_t[0].permute(1,2,0).cpu().numpy()  # [0,1]\n",
        "            bic = make_bicubic_from_lr(lr_rgb, scale=UPSCALE)\n",
        "\n",
        "            # === Métricas PSNR/SSIM (Y + shave 4) ===\n",
        "            sr_y = rgb_to_ycbcr(sr)[...,0:1]\n",
        "            hr_y = rgb_to_ycbcr(hr)[...,0:1]\n",
        "            sr_y_c = shave(sr_y, 4)\n",
        "            hr_y_c = shave(hr_y, 4)\n",
        "            psnr_val = psnr_metric(hr_y_c, sr_y_c, data_range=1.0)\n",
        "            ssim_val = ssim_metric(hr_y_c.squeeze(), sr_y_c.squeeze(), data_range=1.0)\n",
        "            all_psnr.append(psnr_val); all_ssim.append(ssim_val)\n",
        "\n",
        "            # === Salvamento dos arquivos ===\n",
        "            # caminhos\n",
        "            sr_p  = out_dir / f\"sr_{i:02d}.png\"\n",
        "            hr_p  = out_dir / f\"hr_{i:02d}.png\"\n",
        "            bic_p = out_dir / f\"bicubic_{i:02d}.png\"\n",
        "            # orig path (nome fonte da imagem HR no dataset)\n",
        "            try:\n",
        "                original_path = dataset_for_names.hr_paths[i]\n",
        "            except:\n",
        "                original_path = str(hr_p)\n",
        "\n",
        "            # salva completos\n",
        "            np_to_pil(sr).save(sr_p)\n",
        "            np_to_pil(hr).save(hr_p)\n",
        "            np_to_pil(bic).save(bic_p)\n",
        "\n",
        "            # comparativo completo (Bicubic | SR | HR)\n",
        "            cmp_full = concat_horiz([bic, sr, hr])\n",
        "            cmp_full_p = out_dir / f\"compare_full_{i:02d}.png\"\n",
        "            cmp_full.save(cmp_full_p)\n",
        "\n",
        "            # === \"Mesma fatia\" — recorte central idêntico nas 3 imagens ===\n",
        "            H, W = hr.shape[:2]\n",
        "            box = central_crop_box(H, W, min_size=128)\n",
        "            bic_patch = crop_by_box(bic, box)\n",
        "            sr_patch  = crop_by_box(sr,  box)\n",
        "            hr_patch  = crop_by_box(hr,  box)\n",
        "\n",
        "            # salva patches individuais (opcional) e comparativo lado a lado\n",
        "            patch_cmp = concat_horiz([bic_patch, sr_patch, hr_patch])\n",
        "            patch_cmp_p = out_dir / f\"compare_patch_{i:02d}.png\"\n",
        "            patch_cmp.save(patch_cmp_p)\n",
        "\n",
        "            # registra no CSV\n",
        "            writer.writerow([\n",
        "                i, original_path, str(sr_p), str(hr_p), str(bic_p),\n",
        "                str(cmp_full_p), str(patch_cmp_p),\n",
        "                f\"{psnr_val:.4f}\", f\"{ssim_val:.6f}\",\n",
        "                f\"({box[0]},{box[1]},{box[2]},{box[3]})\"\n",
        "            ])\n",
        "\n",
        "            # print resumo para quem está vendo no console\n",
        "            if saved < save_examples:\n",
        "                print(f\"[Exemplo {i}]\")\n",
        "                print(f\"  Original HR: {original_path}\")\n",
        "                print(f\"  SR salvo em: {sr_p.name} | HR: {hr_p.name} | Bicubic: {bic_p.name}\")\n",
        "                print(f\"  Comparação (full): {cmp_full_p.name}\")\n",
        "                print(f\"  Comparação (fatia): {patch_cmp_p.name}  crop_box={box}\")\n",
        "                print(f\"  Métricas (Y, crop 4px): PSNR={psnr_val:.2f}dB  SSIM={ssim_val:.4f}\\n\")\n",
        "                saved += 1\n",
        "\n",
        "    return float(np.mean(all_psnr)), float(np.mean(all_ssim))\n",
        "\n",
        "mean_psnr, mean_ssim = evaluate_model(G, val_dl, val_ds, save_examples=3)\n",
        "print(f\"RESULTADOS (demo) — Y-channel, crop 4 px, x{UPSCALE}:  PSNR={mean_psnr:.2f} dB  SSIM={mean_ssim:.4f}\")\n",
        "print(f\"\\nArquivos salvos em: {root/'out'}\")\n",
        "print(f\"Planilha com caminhos e métricas: {(root/'out'/'examples_info.csv')}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nW0bxQuLD4YJ",
        "outputId": "0a1f0c92-d109-4884-bb8f-b22a86e27b72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Exemplo 0]\n",
            "  Original HR: srgan_demo/data/hr/img_01.png\n",
            "  SR salvo em: sr_00.png | HR: hr_00.png | Bicubic: bicubic_00.png\n",
            "  Comparação (full): compare_full_00.png\n",
            "  Comparação (fatia): compare_patch_00.png  crop_box=(171, 171, 170, 170)\n",
            "  Métricas (Y, crop 4px): PSNR=6.77dB  SSIM=0.0496\n",
            "\n",
            "[Exemplo 1]\n",
            "  Original HR: srgan_demo/data/hr/img_02.png\n",
            "  SR salvo em: sr_01.png | HR: hr_01.png | Bicubic: bicubic_01.png\n",
            "  Comparação (full): compare_full_01.png\n",
            "  Comparação (fatia): compare_patch_01.png  crop_box=(233, 133, 133, 133)\n",
            "  Métricas (Y, crop 4px): PSNR=8.17dB  SSIM=0.0407\n",
            "\n",
            "[Exemplo 2]\n",
            "  Original HR: srgan_demo/data/hr/img_03.png\n",
            "  SR salvo em: sr_02.png | HR: hr_02.png | Bicubic: bicubic_02.png\n",
            "  Comparação (full): compare_full_02.png\n",
            "  Comparação (fatia): compare_patch_02.png  crop_box=(160, 86, 128, 128)\n",
            "  Métricas (Y, crop 4px): PSNR=11.71dB  SSIM=0.1032\n",
            "\n",
            "RESULTADOS (demo) — Y-channel, crop 4 px, x4:  PSNR=8.54 dB  SSIM=0.0635\n",
            "\n",
            "Arquivos salvos em: srgan_demo/out\n",
            "Planilha com caminhos e métricas: srgan_demo/out/examples_info.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Caminho da pasta\n",
        "folder_path = \"/content/srgan_demo/out\"\n",
        "zip_path = \"/content/srgan_out.zip\"\n",
        "\n",
        "# Compacta toda a pasta em um arquivo .zip\n",
        "shutil.make_archive(\"/content/srgan_out_full_files\", 'zip', folder_path)\n",
        "\n",
        "# Faz o download do .zip para seu computador\n",
        "files.download(zip_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Jngy09-mEaJi",
        "outputId": "d34cc140-f0bb-489f-c2a5-e9e85e5b6518"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3396b122-5302-49c4-a0cb-7b121fbef87d\", \"srgan_out.zip\", 1268102)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}